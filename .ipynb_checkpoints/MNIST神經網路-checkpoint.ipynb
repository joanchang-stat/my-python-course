{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 想要提高準確率的方法 :\n",
    "## 1.透過調整神經網路層數或是layer的神經元個數\n",
    "## 2.改變learning rate\n",
    "## 3.改變activation function的種類(relu...)\n",
    "## 4.改變optimizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(x_train,y_train),(x_test,y_test)= mnist.load_data()\n",
    "x_train = x_train.reshape(60000,784)\n",
    "x_test = x_test.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "y_train = np_utils.to_categorical(y_train,10)\n",
    "y_test = np_utils.to_categorical(y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 老師版的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(4,input_dim = 784))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 4)                 3140      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                30        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 3,180\n",
      "Trainable params: 3,180\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse',optimizer=SGD(0.087),metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 12us/step - loss: 0.0901 - acc: 0.1050\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0894 - acc: 0.1985\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0888 - acc: 0.2189\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0884 - acc: 0.1858\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0881 - acc: 0.1886\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0877 - acc: 0.1907\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0874 - acc: 0.1925\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0870 - acc: 0.1949\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0866 - acc: 0.2006\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0862 - acc: 0.2019\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0857 - acc: 0.2022\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0852 - acc: 0.2025\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 10us/step - loss: 0.0847 - acc: 0.2045\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0842 - acc: 0.2052\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0838 - acc: 0.2050\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0833 - acc: 0.2058\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0829 - acc: 0.2056\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0825 - acc: 0.2061A: 0s - loss: 0.0828 - acc:\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 9us/step - loss: 0.0822 - acc: 0.2055\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 8us/step - loss: 0.0819 - acc: 0.2058\n"
     ]
    }
   ],
   "source": [
    "model_20times = model.fit(x_train,y_train,batch_size=100,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact_manual\n",
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(測試編號):\n",
    "    plt.imshow(x_test[測試編號].reshape(28,28),cmap ='Greys')\n",
    "    print('神經網路判斷為 :',predict[測試編號])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "神經網路判斷為 : 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test(53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c934df9ae14b7db60cb244bceb7be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=4999, description='測試編號', max=9999), Button(description='Run Interact', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test(測試編號)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact_manual(test,測試編號=(0,9999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 15us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 0.08153717434406281\n",
      "正確率 0.2082\n"
     ]
    }
   ],
   "source": [
    "print('loss',score[0])\n",
    "print('正確率',score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 改版模型:\n",
    "### 增加層數+改用relu+learning變小+用Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 先正規化資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = (x_train - x_train.min())/(x_train.max() - x_train.min())\n",
    "x_test = (x_test - x_test.min())/(x_test.max() - x_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = Sequential()\n",
    "model_1.add(Dense(5,input_dim = 784))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dense(10))\n",
    "model_1.add(Activation('relu'))\n",
    "model_1.add(Dense(10))\n",
    "model_1.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_17 (Dense)             (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,095\n",
      "Trainable params: 4,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.compile(loss='mse',optimizer=Adadelta(0.02),metrics=['accuracy'])\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 1s 17us/step - loss: 0.0897 - acc: 0.0812 - val_loss: 0.0894 - val_acc: 0.0942\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0891 - acc: 0.1065 - val_loss: 0.0888 - val_acc: 0.1263\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0886 - acc: 0.1367 - val_loss: 0.0882 - val_acc: 0.1596\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0879 - acc: 0.1702 - val_loss: 0.0874 - val_acc: 0.1966\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0870 - acc: 0.2020 - val_loss: 0.0864 - val_acc: 0.2251\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0859 - acc: 0.2218 - val_loss: 0.0853 - val_acc: 0.2380\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0848 - acc: 0.2327 - val_loss: 0.0840 - val_acc: 0.2465\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0835 - acc: 0.2400 - val_loss: 0.0828 - val_acc: 0.2541\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0822 - acc: 0.2476 - val_loss: 0.0815 - val_acc: 0.2638\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0810 - acc: 0.2606 - val_loss: 0.0802 - val_acc: 0.2820\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0798 - acc: 0.2773 - val_loss: 0.0791 - val_acc: 0.2981\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0787 - acc: 0.2961 - val_loss: 0.0780 - val_acc: 0.3169\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0776 - acc: 0.3148 - val_loss: 0.0769 - val_acc: 0.3347\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0766 - acc: 0.3325 - val_loss: 0.0758 - val_acc: 0.3518\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0756 - acc: 0.3479 - val_loss: 0.0748 - val_acc: 0.3670\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0746 - acc: 0.3614 - val_loss: 0.0738 - val_acc: 0.3776\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0737 - acc: 0.3734 - val_loss: 0.0729 - val_acc: 0.3862\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0728 - acc: 0.3850 - val_loss: 0.0720 - val_acc: 0.3979\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0719 - acc: 0.4014 - val_loss: 0.0712 - val_acc: 0.4191\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0711 - acc: 0.4224 - val_loss: 0.0703 - val_acc: 0.4420\n"
     ]
    }
   ],
   "source": [
    "model_1_20times = model_1.fit(x_train,y_train,batch_size = 100,epochs =20,verbose =1,validation_data =(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 14us/step\n",
      "loss 0.07033470211029053\n",
      "正確率 0.442\n"
     ]
    }
   ],
   "source": [
    "score_1 = model_1.evaluate(x_test,y_test)\n",
    "print('loss',score_1[0])\n",
    "print('正確率',score_1[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 才到達0.4!!!也很差!!!再試試調loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(5,input_dim = 784))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(10))\n",
    "model_2.add(Activation('relu'))\n",
    "model_2.add(Dense(10))\n",
    "model_2.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_26 (Dense)             (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,095\n",
      "Trainable params: 4,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss = losses.categorical_crossentropy,optimizer=Adadelta(0.02),metrics=['accuracy'])\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.9271 - acc: 0.7287 - val_loss: 0.8901 - val_acc: 0.7452\n",
      "Epoch 2/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.9024 - acc: 0.7374 - val_loss: 0.8668 - val_acc: 0.7501\n",
      "Epoch 3/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.8798 - acc: 0.7437 - val_loss: 0.8450 - val_acc: 0.7588\n",
      "Epoch 4/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.8587 - acc: 0.7498 - val_loss: 0.8254 - val_acc: 0.7644\n",
      "Epoch 5/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.8393 - acc: 0.7556 - val_loss: 0.8074 - val_acc: 0.7691\n",
      "Epoch 6/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.8215 - acc: 0.7602 - val_loss: 0.7907 - val_acc: 0.7741\n",
      "Epoch 7/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.8050 - acc: 0.7646 - val_loss: 0.7750 - val_acc: 0.7778\n",
      "Epoch 8/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7899 - acc: 0.7688 - val_loss: 0.7609 - val_acc: 0.7811\n",
      "Epoch 9/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7759 - acc: 0.7720 - val_loss: 0.7477 - val_acc: 0.7840\n",
      "Epoch 10/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7629 - acc: 0.7754 - val_loss: 0.7356 - val_acc: 0.7874\n",
      "Epoch 11/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7509 - acc: 0.7788 - val_loss: 0.7243 - val_acc: 0.7885\n",
      "Epoch 12/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7398 - acc: 0.7810 - val_loss: 0.7139 - val_acc: 0.7914\n",
      "Epoch 13/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7296 - acc: 0.7839 - val_loss: 0.7041 - val_acc: 0.7940\n",
      "Epoch 14/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.7201 - acc: 0.7865 - val_loss: 0.6949 - val_acc: 0.7959\n",
      "Epoch 15/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7111 - acc: 0.7894 - val_loss: 0.6863 - val_acc: 0.7984\n",
      "Epoch 16/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.7026 - acc: 0.7915 - val_loss: 0.6786 - val_acc: 0.7998\n",
      "Epoch 17/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6946 - acc: 0.7933 - val_loss: 0.6707 - val_acc: 0.8017\n",
      "Epoch 18/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6871 - acc: 0.7958 - val_loss: 0.6638 - val_acc: 0.8035\n",
      "Epoch 19/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6800 - acc: 0.7983 - val_loss: 0.6567 - val_acc: 0.8051\n",
      "Epoch 20/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6732 - acc: 0.8002 - val_loss: 0.6500 - val_acc: 0.8074\n",
      "Epoch 21/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6667 - acc: 0.8023 - val_loss: 0.6439 - val_acc: 0.8088\n",
      "Epoch 22/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.6606 - acc: 0.8038 - val_loss: 0.6384 - val_acc: 0.8094\n",
      "Epoch 23/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6547 - acc: 0.8049 - val_loss: 0.6326 - val_acc: 0.8116\n",
      "Epoch 24/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.6491 - acc: 0.8067 - val_loss: 0.6270 - val_acc: 0.8137\n",
      "Epoch 25/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6437 - acc: 0.8086 - val_loss: 0.6217 - val_acc: 0.8144\n",
      "Epoch 26/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6387 - acc: 0.8096 - val_loss: 0.6173 - val_acc: 0.8159\n",
      "Epoch 27/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6338 - acc: 0.8105 - val_loss: 0.6125 - val_acc: 0.8178\n",
      "Epoch 28/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6292 - acc: 0.8120 - val_loss: 0.6080 - val_acc: 0.8180\n",
      "Epoch 29/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.6248 - acc: 0.8131 - val_loss: 0.6034 - val_acc: 0.8199\n",
      "Epoch 30/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6205 - acc: 0.8144 - val_loss: 0.5996 - val_acc: 0.8208\n",
      "Epoch 31/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6164 - acc: 0.8152 - val_loss: 0.5952 - val_acc: 0.8220\n",
      "Epoch 32/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6124 - acc: 0.8163 - val_loss: 0.5912 - val_acc: 0.8234\n",
      "Epoch 33/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6086 - acc: 0.8178 - val_loss: 0.5878 - val_acc: 0.8260\n",
      "Epoch 34/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.6049 - acc: 0.8186 - val_loss: 0.5843 - val_acc: 0.8258\n",
      "Epoch 35/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.6014 - acc: 0.8200 - val_loss: 0.5807 - val_acc: 0.8271\n",
      "Epoch 36/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5979 - acc: 0.8212 - val_loss: 0.5769 - val_acc: 0.8283\n",
      "Epoch 37/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5945 - acc: 0.8222 - val_loss: 0.5742 - val_acc: 0.8293\n",
      "Epoch 38/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5912 - acc: 0.8232 - val_loss: 0.5719 - val_acc: 0.8309\n",
      "Epoch 39/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5881 - acc: 0.8242 - val_loss: 0.5680 - val_acc: 0.8315\n",
      "Epoch 40/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5851 - acc: 0.8247 - val_loss: 0.5649 - val_acc: 0.8313\n",
      "Epoch 41/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5821 - acc: 0.8259 - val_loss: 0.5626 - val_acc: 0.8332\n",
      "Epoch 42/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5793 - acc: 0.8264 - val_loss: 0.5594 - val_acc: 0.8332\n",
      "Epoch 43/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5766 - acc: 0.8273 - val_loss: 0.5570 - val_acc: 0.8342\n",
      "Epoch 44/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5739 - acc: 0.8282 - val_loss: 0.5544 - val_acc: 0.8340\n",
      "Epoch 45/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5713 - acc: 0.8291 - val_loss: 0.5516 - val_acc: 0.8344\n",
      "Epoch 46/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5687 - acc: 0.8297 - val_loss: 0.5494 - val_acc: 0.8359\n",
      "Epoch 47/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5662 - acc: 0.8305 - val_loss: 0.5469 - val_acc: 0.8367\n",
      "Epoch 48/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5638 - acc: 0.8310 - val_loss: 0.5446 - val_acc: 0.8378\n",
      "Epoch 49/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5614 - acc: 0.8312 - val_loss: 0.5424 - val_acc: 0.8386\n",
      "Epoch 50/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5590 - acc: 0.8323 - val_loss: 0.5406 - val_acc: 0.8388\n",
      "Epoch 51/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5568 - acc: 0.8332 - val_loss: 0.5382 - val_acc: 0.8401\n",
      "Epoch 52/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5546 - acc: 0.8340 - val_loss: 0.5358 - val_acc: 0.8407\n",
      "Epoch 53/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5524 - acc: 0.8343 - val_loss: 0.5337 - val_acc: 0.8425\n",
      "Epoch 54/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5503 - acc: 0.8348 - val_loss: 0.5318 - val_acc: 0.8428\n",
      "Epoch 55/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5482 - acc: 0.8356 - val_loss: 0.5297 - val_acc: 0.8432\n",
      "Epoch 56/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5462 - acc: 0.8361 - val_loss: 0.5280 - val_acc: 0.8446\n",
      "Epoch 57/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5443 - acc: 0.8369 - val_loss: 0.5259 - val_acc: 0.8451\n",
      "Epoch 58/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5424 - acc: 0.8374 - val_loss: 0.5243 - val_acc: 0.8458\n",
      "Epoch 59/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5406 - acc: 0.8381 - val_loss: 0.5223 - val_acc: 0.8465\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5387 - acc: 0.8384 - val_loss: 0.5207 - val_acc: 0.8472\n",
      "Epoch 61/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5369 - acc: 0.8391 - val_loss: 0.5190 - val_acc: 0.8474\n",
      "Epoch 62/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5351 - acc: 0.8394 - val_loss: 0.5172 - val_acc: 0.8479\n",
      "Epoch 63/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5334 - acc: 0.8403 - val_loss: 0.5154 - val_acc: 0.8488\n",
      "Epoch 64/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5318 - acc: 0.8406 - val_loss: 0.5139 - val_acc: 0.8495\n",
      "Epoch 65/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5301 - acc: 0.8406 - val_loss: 0.5124 - val_acc: 0.8496\n",
      "Epoch 66/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5284 - acc: 0.8416 - val_loss: 0.5107 - val_acc: 0.8505\n",
      "Epoch 67/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5269 - acc: 0.8416 - val_loss: 0.5094 - val_acc: 0.8510\n",
      "Epoch 68/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5253 - acc: 0.8424 - val_loss: 0.5079 - val_acc: 0.8511\n",
      "Epoch 69/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5237 - acc: 0.8430 - val_loss: 0.5064 - val_acc: 0.8514\n",
      "Epoch 70/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5222 - acc: 0.8432 - val_loss: 0.5050 - val_acc: 0.8512\n",
      "Epoch 71/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5207 - acc: 0.8438 - val_loss: 0.5036 - val_acc: 0.8514\n",
      "Epoch 72/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5193 - acc: 0.8446 - val_loss: 0.5026 - val_acc: 0.8520\n",
      "Epoch 73/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5177 - acc: 0.8445 - val_loss: 0.5011 - val_acc: 0.8524\n",
      "Epoch 74/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5164 - acc: 0.8454 - val_loss: 0.4997 - val_acc: 0.8524\n",
      "Epoch 75/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5150 - acc: 0.8457 - val_loss: 0.4984 - val_acc: 0.8528\n",
      "Epoch 76/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5136 - acc: 0.8462 - val_loss: 0.4972 - val_acc: 0.8527\n",
      "Epoch 77/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5123 - acc: 0.8464 - val_loss: 0.4960 - val_acc: 0.8526\n",
      "Epoch 78/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.5110 - acc: 0.8469 - val_loss: 0.4947 - val_acc: 0.8528\n",
      "Epoch 79/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5097 - acc: 0.8470 - val_loss: 0.4939 - val_acc: 0.8529\n",
      "Epoch 80/80\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.5084 - acc: 0.8481 - val_loss: 0.4929 - val_acc: 0.8536\n"
     ]
    }
   ],
   "source": [
    "model_2_80times = model_2.fit(x_train,y_train,batch_size = 100,epochs =80,verbose =1,validation_data =(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 16us/step\n",
      "loss 0.49288329112529755\n",
      "正確率 0.8536\n"
     ]
    }
   ],
   "source": [
    "score_2 = model_2.evaluate(x_test,y_test)\n",
    "print('loss',score_2[0])\n",
    "print('正確率',score_2[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 好像離0.9還差一點!! 將learning調高一點,層數再多一點~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = Sequential()\n",
    "model_3.add(Dense(5,input_dim = 784))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(20))\n",
    "model_3.add(Activation('relu'))\n",
    "model_3.add(Dense(10))\n",
    "model_3.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_35 (Dense)             (None, 5)                 3925      \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 20)                120       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 10)                210       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 4,255\n",
      "Trainable params: 4,255\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.compile(loss = losses.categorical_crossentropy,optimizer=Adadelta(0.5),metrics=['accuracy'])\n",
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/80\n",
      "60000/60000 [==============================] - 1s 21us/step - loss: 0.4856 - acc: 0.8560 - val_loss: 0.4451 - val_acc: 0.8729\n",
      "Epoch 2/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4380 - acc: 0.8720 - val_loss: 0.4159 - val_acc: 0.8805\n",
      "Epoch 3/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.4135 - acc: 0.8793 - val_loss: 0.4032 - val_acc: 0.8820\n",
      "Epoch 4/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3974 - acc: 0.8846 - val_loss: 0.3881 - val_acc: 0.8880\n",
      "Epoch 5/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3861 - acc: 0.8884 - val_loss: 0.3806 - val_acc: 0.8890\n",
      "Epoch 6/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3775 - acc: 0.8908 - val_loss: 0.3724 - val_acc: 0.8919\n",
      "Epoch 7/80\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3709 - acc: 0.8937 - val_loss: 0.3710 - val_acc: 0.8912\n",
      "Epoch 8/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3643 - acc: 0.8953 - val_loss: 0.3627 - val_acc: 0.8933\n",
      "Epoch 9/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3588 - acc: 0.8974 - val_loss: 0.3610 - val_acc: 0.8970\n",
      "Epoch 10/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3545 - acc: 0.8982 - val_loss: 0.3575 - val_acc: 0.8951\n",
      "Epoch 11/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3508 - acc: 0.8994 - val_loss: 0.3526 - val_acc: 0.8967\n",
      "Epoch 12/80\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3470 - acc: 0.9005 - val_loss: 0.3493 - val_acc: 0.8985\n",
      "Epoch 13/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3445 - acc: 0.9007 - val_loss: 0.3469 - val_acc: 0.8994\n",
      "Epoch 14/80\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3417 - acc: 0.9022 - val_loss: 0.3490 - val_acc: 0.9000\n",
      "Epoch 15/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3393 - acc: 0.9027 - val_loss: 0.3440 - val_acc: 0.8999\n",
      "Epoch 16/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3370 - acc: 0.9036 - val_loss: 0.3417 - val_acc: 0.9015\n",
      "Epoch 17/80\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3347 - acc: 0.9039 - val_loss: 0.3414 - val_acc: 0.9000\n",
      "Epoch 18/80\n",
      "60000/60000 [==============================] - 1s 16us/step - loss: 0.3329 - acc: 0.9044 - val_loss: 0.3386 - val_acc: 0.9015\n",
      "Epoch 19/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3305 - acc: 0.9052 - val_loss: 0.3417 - val_acc: 0.9018\n",
      "Epoch 20/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3289 - acc: 0.9058 - val_loss: 0.3397 - val_acc: 0.9013\n",
      "Epoch 21/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3273 - acc: 0.9059 - val_loss: 0.3400 - val_acc: 0.9026\n",
      "Epoch 22/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3260 - acc: 0.9068 - val_loss: 0.3375 - val_acc: 0.9039\n",
      "Epoch 23/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3241 - acc: 0.9076 - val_loss: 0.3345 - val_acc: 0.9010\n",
      "Epoch 24/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3226 - acc: 0.9077 - val_loss: 0.3360 - val_acc: 0.9044\n",
      "Epoch 25/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3216 - acc: 0.9077 - val_loss: 0.3331 - val_acc: 0.9034\n",
      "Epoch 26/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3196 - acc: 0.9086 - val_loss: 0.3330 - val_acc: 0.9025\n",
      "Epoch 27/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3183 - acc: 0.9087 - val_loss: 0.3304 - val_acc: 0.9067\n",
      "Epoch 28/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3168 - acc: 0.9090 - val_loss: 0.3355 - val_acc: 0.9003\n",
      "Epoch 29/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3160 - acc: 0.9092 - val_loss: 0.3306 - val_acc: 0.9040\n",
      "Epoch 30/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3147 - acc: 0.9087 - val_loss: 0.3331 - val_acc: 0.9019\n",
      "Epoch 31/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3134 - acc: 0.9094 - val_loss: 0.3268 - val_acc: 0.9046\n",
      "Epoch 32/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3125 - acc: 0.9100 - val_loss: 0.3276 - val_acc: 0.9043\n",
      "Epoch 33/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3112 - acc: 0.9103 - val_loss: 0.3314 - val_acc: 0.9018\n",
      "Epoch 34/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3110 - acc: 0.9096 - val_loss: 0.3264 - val_acc: 0.9062\n",
      "Epoch 35/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3095 - acc: 0.9105 - val_loss: 0.3270 - val_acc: 0.9061\n",
      "Epoch 36/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3084 - acc: 0.9107 - val_loss: 0.3235 - val_acc: 0.9064\n",
      "Epoch 37/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3080 - acc: 0.9109 - val_loss: 0.3275 - val_acc: 0.9041\n",
      "Epoch 38/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3073 - acc: 0.9113 - val_loss: 0.3308 - val_acc: 0.8996\n",
      "Epoch 39/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3058 - acc: 0.9114 - val_loss: 0.3250 - val_acc: 0.9038\n",
      "Epoch 40/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3048 - acc: 0.9115 - val_loss: 0.3241 - val_acc: 0.9073\n",
      "Epoch 41/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3042 - acc: 0.9111 - val_loss: 0.3288 - val_acc: 0.9085\n",
      "Epoch 42/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3036 - acc: 0.9121 - val_loss: 0.3240 - val_acc: 0.9043\n",
      "Epoch 43/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3028 - acc: 0.9122 - val_loss: 0.3246 - val_acc: 0.9076\n",
      "Epoch 44/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3019 - acc: 0.9126 - val_loss: 0.3218 - val_acc: 0.9047\n",
      "Epoch 45/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.3009 - acc: 0.9125 - val_loss: 0.3209 - val_acc: 0.9066\n",
      "Epoch 46/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.3003 - acc: 0.9129 - val_loss: 0.3222 - val_acc: 0.9041\n",
      "Epoch 47/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2997 - acc: 0.9124 - val_loss: 0.3247 - val_acc: 0.9028\n",
      "Epoch 48/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2993 - acc: 0.9120 - val_loss: 0.3219 - val_acc: 0.9039\n",
      "Epoch 49/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2984 - acc: 0.9132 - val_loss: 0.3193 - val_acc: 0.9074\n",
      "Epoch 50/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2976 - acc: 0.9134 - val_loss: 0.3283 - val_acc: 0.9039\n",
      "Epoch 51/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2973 - acc: 0.9127 - val_loss: 0.3226 - val_acc: 0.9077\n",
      "Epoch 52/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2967 - acc: 0.9133 - val_loss: 0.3183 - val_acc: 0.9066\n",
      "Epoch 53/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2961 - acc: 0.9135 - val_loss: 0.3223 - val_acc: 0.9043\n",
      "Epoch 54/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2954 - acc: 0.9137 - val_loss: 0.3210 - val_acc: 0.9047\n",
      "Epoch 55/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2949 - acc: 0.9139 - val_loss: 0.3196 - val_acc: 0.9051\n",
      "Epoch 56/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2942 - acc: 0.9142 - val_loss: 0.3188 - val_acc: 0.9058\n",
      "Epoch 57/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2932 - acc: 0.9139 - val_loss: 0.3178 - val_acc: 0.9087\n",
      "Epoch 58/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2931 - acc: 0.9139 - val_loss: 0.3179 - val_acc: 0.9079\n",
      "Epoch 59/80\n",
      "60000/60000 [==============================] - 1s 15us/step - loss: 0.2922 - acc: 0.9147 - val_loss: 0.3169 - val_acc: 0.9068\n",
      "Epoch 60/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2916 - acc: 0.9146 - val_loss: 0.3188 - val_acc: 0.9047\n",
      "Epoch 61/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2910 - acc: 0.9148 - val_loss: 0.3184 - val_acc: 0.9075\n",
      "Epoch 62/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2902 - acc: 0.9149 - val_loss: 0.3194 - val_acc: 0.9053\n",
      "Epoch 63/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2894 - acc: 0.9148 - val_loss: 0.3174 - val_acc: 0.9055\n",
      "Epoch 64/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2895 - acc: 0.9146 - val_loss: 0.3205 - val_acc: 0.9065\n",
      "Epoch 65/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2886 - acc: 0.9149 - val_loss: 0.3109 - val_acc: 0.9079\n",
      "Epoch 66/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2883 - acc: 0.9152 - val_loss: 0.3154 - val_acc: 0.9064\n",
      "Epoch 67/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2871 - acc: 0.9153 - val_loss: 0.3204 - val_acc: 0.9046\n",
      "Epoch 68/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2869 - acc: 0.9154 - val_loss: 0.3166 - val_acc: 0.9057\n",
      "Epoch 69/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2867 - acc: 0.9154 - val_loss: 0.3152 - val_acc: 0.9059\n",
      "Epoch 70/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2860 - acc: 0.9150 - val_loss: 0.3132 - val_acc: 0.9084\n",
      "Epoch 71/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2860 - acc: 0.9155 - val_loss: 0.3102 - val_acc: 0.9093\n",
      "Epoch 72/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2858 - acc: 0.9158 - val_loss: 0.3120 - val_acc: 0.9090\n",
      "Epoch 73/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2852 - acc: 0.9163 - val_loss: 0.3117 - val_acc: 0.9074\n",
      "Epoch 74/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2845 - acc: 0.9161 - val_loss: 0.3137 - val_acc: 0.9070\n",
      "Epoch 75/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2841 - acc: 0.9161 - val_loss: 0.3123 - val_acc: 0.9087\n",
      "Epoch 76/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2837 - acc: 0.9160 - val_loss: 0.3112 - val_acc: 0.9065\n",
      "Epoch 77/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2836 - acc: 0.9153 - val_loss: 0.3135 - val_acc: 0.9074\n",
      "Epoch 78/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2830 - acc: 0.9160 - val_loss: 0.3118 - val_acc: 0.9076\n",
      "Epoch 79/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2827 - acc: 0.9167 - val_loss: 0.3135 - val_acc: 0.9073\n",
      "Epoch 80/80\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.2821 - acc: 0.9171 - val_loss: 0.3169 - val_acc: 0.9063\n"
     ]
    }
   ],
   "source": [
    "model_3_80times = model_3.fit(x_train,y_train,batch_size = 100,epochs =80,verbose =1,validation_data =(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 17us/step\n",
      "loss 0.3169358339875937\n",
      "正確率 0.9063\n"
     ]
    }
   ],
   "source": [
    "score_3 = model_3.evaluate(x_test,y_test)\n",
    "print('loss',score_3[0])\n",
    "print('正確率',score_3[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 終於達到9成以上!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
